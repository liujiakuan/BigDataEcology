当spark遇到action类算子，开始调起任务

1.Action类型的算子触发job的执行。源码中调用了SparkContext的runJob()方法，根进源码发现底层调用的是DAGScheduler的runJob()方法。

2.DAGScheduler会将我们的job按照宽窄依赖划分为一个个stage(每个stage根据RDD的Partition的个数决定task的个数)，每个stage中有一组并行计算的task，每一个task都可以看做是一个pipeline，这个管道里面数据是一条一条被计算的，每经过一个RDD会经过一次处理，RDD是一个抽象的概念里面存储的是一些计算的逻辑，每一条数据计算完成之后会在shuffle write过程中将数据落地写入我们的磁盘中。

3.stage划分完之后会以TaskSet的形式（实际上是task的list集合）提交给我们的TaskScheduler。（将 Taskset 传给底层调度器

a）– spark-cluster TaskScheduler

b）– yarn-cluster YarnClusterScheduler

c）– yarn-client YarnClientClusterScheduler）TaskScheduler接收到TaskSet之后会进行遍历，将每个元素依次调用launchTask()方法，launchTask()根据数据本地化的算法发送task到指定的Executor中执行。task在发送到Executor之前首先进行序列化，Executor中有ThreadPool，ThreadPool中有很多线程，在这里面来具体执行我们的task。

4.TaskScheduler和Executor之间有通信（Executor有一个邮箱（消息循环体CoresExecutorGraintedBackend））,Executor接收到task后首先将task反序列化（得到task的list集合），反序列化后将这个task变为taskRunner（new taskRunner）,Executor中的ThreadPool中启动相应的线程接收并且计算相应的task任务。

5.Executor接收到task任务先执行stage1中的task，计算结果会在shuffle write阶段数据落地，数据落地会根据我们的分区策略写入不同的磁盘小文件中，stage1中task全部执行完以后，会向Driver中的DAGScheduler对象里面的MapOutPutTracker发送每一个task的执行状态，以及生成的中间文件的地址。然后，stage2的task开始执行，stage2中task的输入数据就是stage1中task的输出数据，stage2中的task会先向Driver中MapOutPutTracker请求上一批中间文件的地址，拿到地址后stage2-task所在的Executor里面的BlockManager向stage1- task所在的Executor先建立连接，连接是由ConnectionManager负责的，然后由BlockTransformService去拉取数据，（如果使用到了广播变量，stage1-task或者stage2-task会先向它所在的Executor中的BlockManager要广播变量，没有的话，本地的BlockManager会去连接Driver中的BlockManagerMaster，连接完成之后由BlockTransformService将广播变量拉取过来）

6.程序按照上述流程执行直到最后一个stage执行完毕，最后一个stage输出的结果即程序最终输出结果。